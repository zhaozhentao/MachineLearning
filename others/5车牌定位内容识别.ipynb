{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "车牌定位内容识别.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz3b7vGaGBmy"
      },
      "source": [
        "!gdown --id '1lfeLzSgj09icKQT9Yrrvl3quFrwTN9bb' --output data.zip\n",
        "!unzip data.zip\n",
        "\n",
        "!gdown --id '1SCU327iM3Yj8aYCpJLpQmocD3G7hGCWf' --output zc.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32ugUfhVGv2y"
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iESGR8RLtVXF"
      },
      "source": [
        "!rm -rf dataset/error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuRlgiGPMXqh"
      },
      "source": [
        "目标(车牌)检测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU9LDZ5uF_Fm"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "width = 416\n",
        "height = 416\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path + '/img.png')\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [width, height])\n",
        "    img /= 255.0\n",
        "\n",
        "    label = tf.io.read_file(path + '/label.png')\n",
        "    label = tf.image.decode_jpeg(label, channels=3)\n",
        "    label = tf.image.resize(label, [width, height])\n",
        "    # 3 通道降为 1 通道\n",
        "    label = tf.image.rgb_to_grayscale(label)\n",
        "    label /= 38.0\n",
        "\n",
        "    return img, label\n",
        "\n",
        "\n",
        "def unet_model(output_channels):\n",
        "    inputs = tf.keras.layers.Input(shape=[width, height, 3])\n",
        "    x = inputs\n",
        "\n",
        "    # 在模型中降频取样\n",
        "    skips = down_stack(x)\n",
        "    x = skips[-1]\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # 升频取样然后建立跳跃连接\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        concat = tf.keras.layers.Concatenate()\n",
        "        x = concat([x, skip])\n",
        "\n",
        "    # 这是模型的最后一层\n",
        "    last = tf.keras.layers.Conv2DTranspose(\n",
        "        output_channels, 3, strides=2,\n",
        "        padding='same')  # 64x64 -> 128x128\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "\n",
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i + 1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]\n",
        "\n",
        "\n",
        "def show_predictions(dataset=None, num=2):\n",
        "    if dataset:\n",
        "        for img, mask in dataset.take(num):\n",
        "            pred_mask = model.predict(img)\n",
        "            display([img[0], mask[0], create_mask(pred_mask)])\n",
        "    else:\n",
        "        display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tBTH1UMPhF4"
      },
      "source": [
        "batch_size = 32\n",
        "output_channels = 3\n",
        "all_image_paths = [str(path) for path in pathlib.Path('./dataset').glob('*/*')]\n",
        "image_count = len(all_image_paths)\n",
        "steps_per_epoch = tf.math.ceil(image_count / batch_size).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr2hqj5lPrWe"
      },
      "source": [
        "np.random.shuffle(all_image_paths)\n",
        "\n",
        "valid_count = int((tf.math.floor(image_count / 10)).numpy())\n",
        "\n",
        "valid_image_path = all_image_paths[0 : valid_count]\n",
        "\n",
        "train_image_path = all_image_paths[valid_count : ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSjVtm0Ayz1D"
      },
      "source": [
        "image_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_image_path)\n",
        "        .map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "train_dataset = (\n",
        "    image_ds.cache()\n",
        "        .shuffle(image_count)\n",
        "        .repeat()\n",
        "        .batch(batch_size)\n",
        "        .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "for image, mask in image_ds.take(2):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "display([sample_image, sample_mask])\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[width, height, 3], include_top=False)\n",
        "\n",
        "# 使用这些层的激活设置\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',  # 64x64\n",
        "    'block_3_expand_relu',  # 32x32\n",
        "    'block_6_expand_relu',  # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',  # 4x4\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# 创建特征提取模型\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False\n",
        "\n",
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),  # 32x32 -> 64x64\n",
        "]\n",
        "\n",
        "model = unet_model(output_channels)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R4wAvaSo_0xJ"
      },
      "source": [
        "show_predictions()\n",
        "\n",
        "model_history = model.fit(train_dataset, epochs=10, steps_per_epoch=steps_per_epoch)\n",
        "\n",
        "show_predictions(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVkoqAtdWtKs",
        "outputId": "8b0c932a-bc7b-496e-bc1e-46e2deaf5791"
      },
      "source": [
        "valid_ds = (\n",
        "  tf.data.Dataset.from_tensor_slices(valid_image_path)\n",
        "    .map(load_and_preprocess_image, tf.data.experimental.AUTOTUNE)\n",
        "    .cache()\n",
        "    .batch(100)\n",
        "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)    \n",
        ")\n",
        "\n",
        "model.evaluate(valid_ds, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 - 7s - loss: 0.0044 - accuracy: 0.9840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.004411337897181511, 0.9840132594108582]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVd2jlYJYz2i"
      },
      "source": [
        "show_predictions(valid_ds, 1)\n",
        "\n",
        "model.save('zc.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QynHCk-I_367"
      },
      "source": [
        "根据人工标记label裁剪车牌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZauKHVeWnFWf"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def locate(img_src, img_mask, dir_path):\n",
        "    contours, hierarchy = cv2.findContours(img_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 获取边缘区域宽度最大的区域\n",
        "    cont = max(contours, key=lambda item: cv2.boundingRect(item)[2])\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(cont)  # 获取最小外接矩形\n",
        "\n",
        "    if w > 15 and h > 15:\n",
        "        rect = cv2.minAreaRect(cont)  # 针对坐标点获取带方向角的最小外接矩形，中心点坐标，宽高，旋转角度\n",
        "        box = cv2.boxPoints(rect).astype(np.int32)  # 获取最小外接矩形四个顶点坐标\n",
        "\n",
        "        cont = cont.reshape(-1, 2).tolist()\n",
        "        # 由于转换矩阵的两组坐标位置需要一一对应，因此需要将最小外接矩形的坐标进行排序，最终排序为[左上，左下，右上，右下]\n",
        "        box = sorted(box, key=lambda xy: xy[0])  # 先按照左右进行排序，分为左侧的坐标和右侧的坐标\n",
        "        box_left, box_right = box[:2], box[2:]  # 此时box的前2个是左侧的坐标，后2个是右侧的坐标\n",
        "        box_left = sorted(box_left, key=lambda x: x[1])  # 再按照上下即y进行排序，此时box_left中为左上和左下两个端点坐标\n",
        "        box_right = sorted(box_right, key=lambda x: x[1])  # 此时box_right中为右上和右下两个端点坐标\n",
        "        box = np.array(box_left + box_right)  # [左上，左下，右上，右下]\n",
        "\n",
        "        x0, y0 = box[0][0], box[0][1]  # 这里的4个坐标即为最小外接矩形的四个坐标，接下来需获取平行(或不规则)四边形的坐标\n",
        "        x1, y1 = box[1][0], box[1][1]\n",
        "        x2, y2 = box[2][0], box[2][1]\n",
        "        x3, y3 = box[3][0], box[3][1]\n",
        "\n",
        "        def point_to_line_distance(X, Y):\n",
        "            if x2 - x0:\n",
        "                k_up = (y2 - y0) / (x2 - x0)  # 斜率不为无穷大\n",
        "                d_up = abs(k_up * X - Y + y2 - k_up * x2) / (k_up ** 2 + 1) ** 0.5\n",
        "            else:  # 斜率无穷大\n",
        "                d_up = abs(X - x2)\n",
        "            if x1 - x3:\n",
        "                k_down = (y1 - y3) / (x1 - x3)  # 斜率不为无穷大\n",
        "                d_down = abs(k_down * X - Y + y1 - k_down * x1) / (k_down ** 2 + 1) ** 0.5\n",
        "            else:  # 斜率无穷大\n",
        "                d_down = abs(X - x1)\n",
        "            return d_up, d_down\n",
        "\n",
        "        d0, d1, d2, d3 = np.inf, np.inf, np.inf, np.inf\n",
        "        l0, l1, l2, l3 = (x0, y0), (x1, y1), (x2, y2), (x3, y3)\n",
        "        for each in cont:  # 计算cont中的坐标与矩形四个坐标的距离以及到上下两条直线的距离，对距离和进行权重的添加，成功选出四边形的4个顶点坐标\n",
        "            x, y = each[0], each[1]\n",
        "            dis0 = (x - x0) ** 2 + (y - y0) ** 2\n",
        "            dis1 = (x - x1) ** 2 + (y - y1) ** 2\n",
        "            dis2 = (x - x2) ** 2 + (y - y2) ** 2\n",
        "            dis3 = (x - x3) ** 2 + (y - y3) ** 2\n",
        "            d_up, d_down = point_to_line_distance(x, y)\n",
        "            weight = 0.975\n",
        "            if weight * d_up + (1 - weight) * dis0 < d0:\n",
        "                d0 = weight * d_up + (1 - weight) * dis0\n",
        "                l0 = (x - 4, y - 2)\n",
        "            if weight * d_down + (1 - weight) * dis1 < d1:\n",
        "                d1 = weight * d_down + (1 - weight) * dis1\n",
        "                l1 = (x - 4, y + 2)\n",
        "            if weight * d_up + (1 - weight) * dis2 < d2:\n",
        "                d2 = weight * d_up + (1 - weight) * dis2\n",
        "                l2 = (x + 4, y - 2)\n",
        "            if weight * d_down + (1 - weight) * dis3 < d3:\n",
        "                d3 = weight * d_down + (1 - weight) * dis3\n",
        "                l3 = (x + 4, y + 2)\n",
        "\n",
        "        p0 = np.float32([l0, l1, l2, l3])  # 左上角，左下角，右上角，右下角，形成的新box顺序需和原box中的顺序对应，以进行转换矩阵的形成\n",
        "        p1 = np.float32([(0, 0), (0, 80), (240, 0), (240, 80)])\n",
        "        transform_mat = cv2.getPerspectiveTransform(p0, p1)  # 构成转换矩阵\n",
        "        lic = cv2.warpPerspective(img_src, transform_mat, (240, 80))  # 进行车牌矫正\n",
        "\n",
        "        print('saving ' + dir_path)\n",
        "        tf.io.write_file(dir_path + '/plate.jpeg', tf.image.encode_jpeg(lic))\n",
        "\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]\n",
        "\n",
        "\n",
        "image_dirs = [str(path) for path in pathlib.Path('dataset').glob('*/*')]\n",
        "\n",
        "for dir_path in image_dirs:\n",
        "    file_path = dir_path + '/img.png'\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    mask = tf.io.read_file(dir_path + '/label.png')\n",
        "    mask = tf.image.decode_jpeg(mask, channels=1)\n",
        "\n",
        "    image = np.asarray(image)\n",
        "    mask = np.asarray(mask)\n",
        "\n",
        "    locate(image, mask, str(pathlib.Path(file_path).parent))\n",
        "\n",
        "print('finish')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQOELq_ZOdTO"
      },
      "source": [
        "利用裁剪出来的车牌训练内容识别"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GBaUSbeyEZx"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "char_dict = {\"京\": 0, \"沪\": 1, \"津\": 2, \"渝\": 3, \"冀\": 4, \"晋\": 5, \"蒙\": 6, \"辽\": 7, \"吉\": 8, \"黑\": 9, \"苏\": 10,\n",
        "             \"浙\": 11, \"皖\": 12, \"闽\": 13, \"赣\": 14, \"鲁\": 15, \"豫\": 16, \"鄂\": 17, \"湘\": 18, \"粤\": 19, \"桂\": 20,\n",
        "             \"琼\": 21, \"川\": 22, \"贵\": 23, \"云\": 24, \"藏\": 25, \"陕\": 26, \"甘\": 27, \"青\": 28, \"宁\": 29, \"新\": 30,\n",
        "             \"0\": 31, \"1\": 32, \"2\": 33, \"3\": 34, \"4\": 35, \"5\": 36, \"6\": 37, \"7\": 38, \"8\": 39, \"9\": 40,\n",
        "             \"A\": 41, \"B\": 42, \"C\": 43, \"D\": 44, \"E\": 45, \"F\": 46, \"G\": 47, \"H\": 48, \"J\": 49, \"K\": 50,\n",
        "             \"L\": 51, \"M\": 52, \"N\": 53, \"P\": 54, \"Q\": 55, \"R\": 56, \"S\": 57, \"T\": 58, \"U\": 59, \"V\": 60,\n",
        "             \"W\": 61, \"X\": 62, \"Y\": 63, \"Z\": 64, \"\": 65}\n",
        "\n",
        "# 读取数据集\n",
        "all_image_path = [str(p) for p in pathlib.Path('./dataset').glob('*/*')]\n",
        "\n",
        "n = len(all_image_path)\n",
        "X_train, y_train = [], []\n",
        "idx = 0\n",
        "for i in range(n):\n",
        "    path = all_image_path[i]\n",
        "    print('正在读取 {}'.format(all_image_path[i]))\n",
        "    img = tf.io.read_file(path + '/plate.jpeg')\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [80, 240])\n",
        "    img /= 255.0\n",
        "\n",
        "    plate = pathlib.Path(path).name\n",
        "    label = [char_dict[name] for name in plate[0:8]]  # 图片名前7位为车牌标签\n",
        "    if len(label) == 7:\n",
        "      label.append(65)\n",
        "    X_train.append(img)\n",
        "    y_train.append(label)\n",
        "    if idx == 0:\n",
        "      plt.imshow(img)\n",
        "      plt.show()\n",
        "      idx = 1\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = [np.array(y_train)[:, i] for i in range(8)]\n",
        "\n",
        "input = tf.keras.layers.Input((80, 240, 3))\n",
        "x = input\n",
        "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same', strides=2)(x)\n",
        "for i in range(3):\n",
        "    x = tf.keras.layers.Conv2D(filters=32 * 2 ** i, kernel_size=(3, 3), padding='valid', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=32 * 2 ** i, kernel_size=(3, 3), padding='valid', activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same', strides=2)(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "Output = [tf.keras.layers.Dense(66, activation='softmax', name='c%d' % (i + 1))(x) for i in range(8)]\n",
        "\n",
        "model = tf.keras.models.Model(inputs=input, outputs=Output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdaGq9uTqLgb"
      },
      "source": [
        "model.evaluate(X_train, y_train)\n",
        "\n",
        "model.save('plate.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bo2BD2SDedA"
      },
      "source": [
        "定位车牌和车牌识别\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHRvT7mwDjgR"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "char_dict = {\"京\": 0, \"沪\": 1, \"津\": 2, \"渝\": 3, \"冀\": 4, \"晋\": 5, \"蒙\": 6, \"辽\": 7, \"吉\": 8, \"黑\": 9, \"苏\": 10,\n",
        "             \"浙\": 11, \"皖\": 12, \"闽\": 13, \"赣\": 14, \"鲁\": 15, \"豫\": 16, \"鄂\": 17, \"湘\": 18, \"粤\": 19, \"桂\": 20,\n",
        "             \"琼\": 21, \"川\": 22, \"贵\": 23, \"云\": 24, \"藏\": 25, \"陕\": 26, \"甘\": 27, \"青\": 28, \"宁\": 29, \"新\": 30,\n",
        "             \"0\": 31, \"1\": 32, \"2\": 33, \"3\": 34, \"4\": 35, \"5\": 36, \"6\": 37, \"7\": 38, \"8\": 39, \"9\": 40,\n",
        "             \"A\": 41, \"B\": 42, \"C\": 43, \"D\": 44, \"E\": 45, \"F\": 46, \"G\": 47, \"H\": 48, \"J\": 49, \"K\": 50,\n",
        "             \"L\": 51, \"M\": 52, \"N\": 53, \"P\": 54, \"Q\": 55, \"R\": 56, \"S\": 57, \"T\": 58, \"U\": 59, \"V\": 60,\n",
        "             \"W\": 61, \"X\": 62, \"Y\": 63, \"Z\": 64, \"\": 65}\n",
        "\n",
        "index_to_char = [\n",
        "    \"京\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\",\n",
        "    \"浙\", \"皖\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\",\n",
        "    \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\",\n",
        "    \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n",
        "    \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"J\", \"K\",\n",
        "    \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\",\n",
        "    \"W\", \"X\", \"Y\", \"Z\", \"\"\n",
        "]\n",
        "\n",
        "\n",
        "def locate(img_src, img_mask):\n",
        "    contours, hierarchy = cv2.findContours(img_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 获取边缘区域宽度最大的区域\n",
        "    cont = max(contours, key=lambda item: cv2.boundingRect(item)[2])\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(cont)  # 获取最小外接矩形\n",
        "\n",
        "    if w > 15 and h > 15:\n",
        "        rect = cv2.minAreaRect(cont)  # 针对坐标点获取带方向角的最小外接矩形，中心点坐标，宽高，旋转角度\n",
        "        box = cv2.boxPoints(rect).astype(np.int32)  # 获取最小外接矩形四个顶点坐标\n",
        "\n",
        "        cont = cont.reshape(-1, 2).tolist()\n",
        "        # 由于转换矩阵的两组坐标位置需要一一对应，因此需要将最小外接矩形的坐标进行排序，最终排序为[左上，左下，右上，右下]\n",
        "        box = sorted(box, key=lambda xy: xy[0])  # 先按照左右进行排序，分为左侧的坐标和右侧的坐标\n",
        "        box_left, box_right = box[:2], box[2:]  # 此时box的前2个是左侧的坐标，后2个是右侧的坐标\n",
        "        box_left = sorted(box_left, key=lambda x: x[1])  # 再按照上下即y进行排序，此时box_left中为左上和左下两个端点坐标\n",
        "        box_right = sorted(box_right, key=lambda x: x[1])  # 此时box_right中为右上和右下两个端点坐标\n",
        "        box = np.array(box_left + box_right)  # [左上，左下，右上，右下]\n",
        "\n",
        "        x0, y0 = box[0][0], box[0][1]  # 这里的4个坐标即为最小外接矩形的四个坐标，接下来需获取平行(或不规则)四边形的坐标\n",
        "        x1, y1 = box[1][0], box[1][1]\n",
        "        x2, y2 = box[2][0], box[2][1]\n",
        "        x3, y3 = box[3][0], box[3][1]\n",
        "\n",
        "        def point_to_line_distance(X, Y):\n",
        "            if x2 - x0:\n",
        "                k_up = (y2 - y0) / (x2 - x0)  # 斜率不为无穷大\n",
        "                d_up = abs(k_up * X - Y + y2 - k_up * x2) / (k_up ** 2 + 1) ** 0.5\n",
        "            else:  # 斜率无穷大\n",
        "                d_up = abs(X - x2)\n",
        "            if x1 - x3:\n",
        "                k_down = (y1 - y3) / (x1 - x3)  # 斜率不为无穷大\n",
        "                d_down = abs(k_down * X - Y + y1 - k_down * x1) / (k_down ** 2 + 1) ** 0.5\n",
        "            else:  # 斜率无穷大\n",
        "                d_down = abs(X - x1)\n",
        "            return d_up, d_down\n",
        "\n",
        "        d0, d1, d2, d3 = np.inf, np.inf, np.inf, np.inf\n",
        "        l0, l1, l2, l3 = (x0, y0), (x1, y1), (x2, y2), (x3, y3)\n",
        "        for each in cont:  # 计算cont中的坐标与矩形四个坐标的距离以及到上下两条直线的距离，对距离和进行权重的添加，成功选出四边形的4个顶点坐标\n",
        "            x, y = each[0], each[1]\n",
        "            dis0 = (x - x0) ** 2 + (y - y0) ** 2\n",
        "            dis1 = (x - x1) ** 2 + (y - y1) ** 2\n",
        "            dis2 = (x - x2) ** 2 + (y - y2) ** 2\n",
        "            dis3 = (x - x3) ** 2 + (y - y3) ** 2\n",
        "            d_up, d_down = point_to_line_distance(x, y)\n",
        "            weight = 0.975\n",
        "            if weight * d_up + (1 - weight) * dis0 < d0:\n",
        "                d0 = weight * d_up + (1 - weight) * dis0\n",
        "                l0 = (x - 4, y - 2)\n",
        "            if weight * d_down + (1 - weight) * dis1 < d1:\n",
        "                d1 = weight * d_down + (1 - weight) * dis1\n",
        "                l1 = (x - 4, y + 2)\n",
        "            if weight * d_up + (1 - weight) * dis2 < d2:\n",
        "                d2 = weight * d_up + (1 - weight) * dis2\n",
        "                l2 = (x + 4, y - 2)\n",
        "            if weight * d_down + (1 - weight) * dis3 < d3:\n",
        "                d3 = weight * d_down + (1 - weight) * dis3\n",
        "                l3 = (x + 4, y + 2)\n",
        "\n",
        "        p0 = np.float32([l0, l1, l2, l3])  # 左上角，左下角，右上角，右下角，形成的新box顺序需和原box中的顺序对应，以进行转换矩阵的形成\n",
        "        p1 = np.float32([(0, 0), (0, 80), (240, 0), (240, 80)])\n",
        "        transform_mat = cv2.getPerspectiveTransform(p0, p1)  # 构成转换矩阵\n",
        "        lic = cv2.warpPerspective(img_src, transform_mat, (240, 80))  # 进行车牌矫正\n",
        "\n",
        "        return lic\n",
        "\n",
        "\n",
        "width = 416\n",
        "height = 416\n",
        "images_path = [str(p) for p in pathlib.Path('./dataset').glob('*/*')]\n",
        "detect_model = tf.keras.models.load_model('zc.h5')\n",
        "recognition_model = tf.keras.models.load_model('plate.h5')\n",
        "\n",
        "np.random.shuffle(images_path)\n",
        "\n",
        "error_count = 0\n",
        "idx = 0\n",
        "for p in images_path:\n",
        "    print('idx {}'.format(idx))\n",
        "    idx += 1\n",
        "    img = tf.io.read_file(p + '/img.png')\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [width, height])\n",
        "    raw_img = img\n",
        "    img = img / 255.0\n",
        "\n",
        "\n",
        "    result = detect_model.predict(np.array([img]))\n",
        "\n",
        "    mask = create_mask(result)\n",
        "    mask = tf.keras.preprocessing.image.array_to_img(mask)\n",
        "    mask = np.asarray(mask)\n",
        "    img = np.asarray(img)\n",
        "\n",
        "    plate_image = locate(img, mask)\n",
        "    plate_chars = recognition_model.predict(np.array([plate_image]))\n",
        "    plate = []\n",
        "    for cs in plate_chars:\n",
        "        plate.append(index_to_char[np.argmax(cs)])\n",
        "\n",
        "    real_plate = pathlib.Path(p).name\n",
        "    predict_plate = ''.join(plate)\n",
        "\n",
        "    if predict_plate != real_plate:\n",
        "        print('wrong real plate is {}, predict plate is {}'.format(real_plate, predict_plate))\n",
        "        error_count += 1\n",
        "        raw_img = np.asarray(raw_img)\n",
        "        plate_image = locate(raw_img, mask)\n",
        "        tf.io.write_file('./dataset/error/' + real_plate + '/plate.jpeg', tf.image.encode_jpeg(plate_image))\n",
        "\n",
        "print('total error {}'.format(error_count))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}