{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "2车牌定位.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "xz3b7vGaGBmy"
   },
   "source": [
    "!gdown --id '1lfeLzSgj09icKQT9Yrrvl3quFrwTN9bb' --output data.zip\n",
    "!unzip data.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "32ugUfhVGv2y"
   },
   "source": [
    "!pip install git+https://github.com/tensorflow/examples.git"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GU9LDZ5uF_Fm"
   },
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "width = 416\n",
    "height = 416\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    img = tf.io.read_file(path + '/img.png')\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [width, height])\n",
    "\n",
    "    label = tf.io.read_file(path + '/label.png')\n",
    "    label = tf.image.decode_jpeg(label, channels=1)\n",
    "    label = tf.image.resize(label, [width, height])\n",
    "    label /= 255.0\n",
    "\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def unet_model(output_channels):\n",
    "    inputs = tf.keras.layers.Input(shape=[width, height, 3])\n",
    "    x = inputs\n",
    "\n",
    "    # 在模型中降频取样\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # 升频取样然后建立跳跃连接\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # 这是模型的最后一层\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "        output_channels, 3, strides=2,\n",
    "        padding='same')  # 64x64 -> 128x128\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "def show_predictions(dataset=None, num=2):\n",
    "    if dataset:\n",
    "        for img, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(img)\n",
    "            display([img[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0tBTH1UMPhF4"
   },
   "source": [
    "batch_size = 32\n",
    "output_channels = 1\n",
    "all_image_paths = [str(path) for path in pathlib.Path('./dataset').glob('*/*')]\n",
    "image_count = len(all_image_paths)\n",
    "steps_per_epoch = tf.math.ceil(image_count / batch_size).numpy()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tr2hqj5lPrWe"
   },
   "source": [
    "np.random.shuffle(all_image_paths)\n",
    "\n",
    "valid_count = int((tf.math.floor(image_count / 10)).numpy())\n",
    "\n",
    "valid_image_path = all_image_paths[0 : valid_count]\n",
    "\n",
    "train_image_path = all_image_paths[valid_count : ]"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dSjVtm0Ayz1D"
   },
   "source": [
    "image_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_image_path)\n",
    "        .map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    image_ds.cache()\n",
    "        .shuffle(image_count)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "        .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "for image, mask in image_ds.take(2):\n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "display([sample_image, sample_mask])\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[width, height, 3], include_top=False)\n",
    "\n",
    "# 使用这些层的激活设置\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',  # 64x64\n",
    "    'block_3_expand_relu',  # 32x32\n",
    "    'block_6_expand_relu',  # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',  # 4x4\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# 创建特征提取模型\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "down_stack.trainable = False\n",
    "\n",
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),  # 32x32 -> 64x64\n",
    "]\n",
    "\n",
    "model = unet_model(output_channels)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aYdkvM6ZnFUN"
   },
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R4wAvaSo_0xJ"
   },
   "source": [
    "show_predictions()\n",
    "\n",
    "model_history = model.fit(train_dataset, epochs=30, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "show_predictions(train_dataset)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mVkoqAtdWtKs"
   },
   "source": [
    "valid_ds = (\n",
    "  tf.data.Dataset.from_tensor_slices(valid_image_path)\n",
    "    .map(load_and_preprocess_image, tf.data.experimental.AUTOTUNE)\n",
    "    .cache()\n",
    "    .batch(100)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "model.evaluate(valid_ds, verbose=2)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FVd2jlYJYz2i"
   },
   "source": [
    "show_predictions(valid_ds, 1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZauKHVeWnFWf"
   },
   "source": [
    "import cv2\n",
    "\n",
    "def locate(img_src, img_mask, name):\n",
    "    contours, hierarchy = cv2.findContours(img_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not len(contours):  # contours1长度为0说明未检测到车牌\n",
    "        print(\"未检测到车牌\")\n",
    "    else:\n",
    "        flag = 0  # 默认flag为0，因为不一定有车牌区域\n",
    "        for ii, cont in enumerate(contours):\n",
    "            x, y, w, h = cv2.boundingRect(cont)  # 获取最小外接矩形\n",
    "            img_cut_mask = img_mask[y:y + h, x:x + w]  # 将标签车牌区域截取出来\n",
    "            if w > 15 and h > 15:\n",
    "                rect = cv2.minAreaRect(cont)  # 针对坐标点获取带方向角的最小外接矩形，中心点坐标，宽高，旋转角度\n",
    "                box = cv2.boxPoints(rect).astype(np.int32)  # 获取最小外接矩形四个顶点坐标\n",
    "                cv2.drawContours(img_mask, contours, -1, (0, 0, 255), 2)\n",
    "                cv2.drawContours(img_mask, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "                cont = cont.reshape(-1, 2).tolist()\n",
    "                # 由于转换矩阵的两组坐标位置需要一一对应，因此需要将最小外接矩形的坐标进行排序，最终排序为[左上，左下，右上，右下]\n",
    "                box = sorted(box, key=lambda xy: xy[0])  # 先按照左右进行排序，分为左侧的坐标和右侧的坐标\n",
    "                box_left, box_right = box[:2], box[2:]  # 此时box的前2个是左侧的坐标，后2个是右侧的坐标\n",
    "                box_left = sorted(box_left, key=lambda x: x[1])  # 再按照上下即y进行排序，此时box_left中为左上和左下两个端点坐标\n",
    "                box_right = sorted(box_right, key=lambda x: x[1])  # 此时box_right中为右上和右下两个端点坐标\n",
    "                box = np.array(box_left + box_right)  # [左上，左下，右上，右下]\n",
    "\n",
    "                x0, y0 = box[0][0], box[0][1]  # 这里的4个坐标即为最小外接矩形的四个坐标，接下来需获取平行(或不规则)四边形的坐标\n",
    "                x1, y1 = box[1][0], box[1][1]\n",
    "                x2, y2 = box[2][0], box[2][1]\n",
    "                x3, y3 = box[3][0], box[3][1]\n",
    "\n",
    "                def point_to_line_distance(X, Y):\n",
    "                    if x2 - x0:\n",
    "                        k_up = (y2 - y0) / (x2 - x0)  # 斜率不为无穷大\n",
    "                        d_up = abs(k_up * X - Y + y2 - k_up * x2) / (k_up ** 2 + 1) ** 0.5\n",
    "                    else:  # 斜率无穷大\n",
    "                        d_up = abs(X - x2)\n",
    "                    if x1 - x3:\n",
    "                        k_down = (y1 - y3) / (x1 - x3)  # 斜率不为无穷大\n",
    "                        d_down = abs(k_down * X - Y + y1 - k_down * x1) / (k_down ** 2 + 1) ** 0.5\n",
    "                    else:  # 斜率无穷大\n",
    "                        d_down = abs(X - x1)\n",
    "                    return d_up, d_down\n",
    "\n",
    "                d0, d1, d2, d3 = np.inf, np.inf, np.inf, np.inf\n",
    "                l0, l1, l2, l3 = (x0, y0), (x1, y1), (x2, y2), (x3, y3)\n",
    "                for each in cont:  # 计算cont中的坐标与矩形四个坐标的距离以及到上下两条直线的距离，对距离和进行权重的添加，成功选出四边形的4个顶点坐标\n",
    "                    x, y = each[0], each[1]\n",
    "                    dis0 = (x - x0) ** 2 + (y - y0) ** 2\n",
    "                    dis1 = (x - x1) ** 2 + (y - y1) ** 2\n",
    "                    dis2 = (x - x2) ** 2 + (y - y2) ** 2\n",
    "                    dis3 = (x - x3) ** 2 + (y - y3) ** 2\n",
    "                    d_up, d_down = point_to_line_distance(x, y)\n",
    "                    weight = 0.975\n",
    "                    if weight * d_up + (1 - weight) * dis0 < d0:\n",
    "                        d0 = weight * d_up + (1 - weight) * dis0\n",
    "                        l0 = (x, y)\n",
    "                    if weight * d_down + (1 - weight) * dis1 < d1:\n",
    "                        d1 = weight * d_down + (1 - weight) * dis1\n",
    "                        l1 = (x, y)\n",
    "                    if weight * d_up + (1 - weight) * dis2 < d2:\n",
    "                        d2 = weight * d_up + (1 - weight) * dis2\n",
    "                        l2 = (x, y)\n",
    "                    if weight * d_down + (1 - weight) * dis3 < d3:\n",
    "                        d3 = weight * d_down + (1 - weight) * dis3\n",
    "                        l3 = (x, y)\n",
    "\n",
    "                p0 = np.float32([l0, l1, l2, l3])  # 左上角，左下角，右上角，右下角，形成的新box顺序需和原box中的顺序对应，以进行转换矩阵的形成\n",
    "                p1 = np.float32([(0, 0), (0, 80), (240, 0), (240, 80)])\n",
    "                transform_mat = cv2.getPerspectiveTransform(p0, p1)  # 构成转换矩阵\n",
    "                lic = cv2.warpPerspective(img_src, transform_mat, (240, 80))  # 进行车牌矫正\n",
    "\n",
    "                if len(contours) == 1:  # 只有一个区域可以认为是车牌区域\n",
    "                    flag += 1\n",
    "                    print('saving ', save_path + name[0:7] + '.png')\n",
    "                    tf.io.write_file('./plate.jpeg', tf.image.encode_jpeg(lic))\n",
    "\n",
    "        if not flag:\n",
    "            print(\"未检测到车牌区域或车牌区域过小\")\n",
    "\n",
    "\n",
    "save_path = ''\n",
    "\n",
    "for images, masks in valid_ds.take(1):\n",
    "  for img in images:\n",
    "    img = tf.keras.preprocessing.image.array_to_img(img)\n",
    "    i = np.asarray(img)\n",
    "    break\n",
    "  for mask in masks:\n",
    "    mask = tf.keras.preprocessing.image.array_to_img(mask)\n",
    "    m = np.asarray(mask)\n",
    "    break\n",
    "\n",
    "  locate(i, m, 'sdfsdfsdf')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}