{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasKeypointDetect.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Gu3YKTD3wyl"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U imgaug"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 下载斯坦福数据集公开部分"
      ],
      "metadata": {
        "id": "hU_6DsZk53Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
        "!tar xf images.tar"
      ],
      "metadata": {
        "id": "6aZVaNKL51vT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 下载申请回来的斯坦福数据集"
      ],
      "metadata": {
        "id": "zjSah75NB2Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown '1v5w2lMfjE3FZRPXsJKUli7NaKhVFvBGj'\n",
        "!unzip stanfordextra_v12.zip"
      ],
      "metadata": {
        "id": "_RZ9sKCzA32f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from imgaug.augmentables.kps import KeypointsOnImage\n",
        "from imgaug.augmentables.kps import Keypoint\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "8wolMdVe6WbG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 设置超参数"
      ],
      "metadata": {
        "id": "-4XSCHPeKahz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "NUM_KEYPOINTS = 24 * 2  # 24 pairs each having x and y coordinates"
      ],
      "metadata": {
        "id": "qlN5TVlY6dvm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_DIR = \"Images\"\n",
        "JSON = \"StanfordExtra_V12/StanfordExtra_v12.json\"\n",
        "KEYPOINT_DEF = (\n",
        "    \"https://github.com/benjiebob/StanfordExtra/raw/master/keypoint_definitions.csv\"\n",
        ")\n",
        "\n",
        "# Load the ground-truth annotations.\n",
        "with open(JSON) as infile:\n",
        "    json_data = json.load(infile)\n",
        "\n",
        "# Set up a dictionary, mapping all the ground-truth information\n",
        "# with respect to the path of the image.\n",
        "json_dict = {i[\"img_path\"]: i for i in json_data}"
      ],
      "metadata": {
        "id": "QWtnbvhP6e5g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keypoint_def = pd.read_csv(KEYPOINT_DEF)\n",
        "keypoint_def.head()\n",
        "\n",
        "# Extract the colours and labels.\n",
        "colours = keypoint_def[\"Hex colour\"].values.tolist()\n",
        "colours = [\"#\" + colour for colour in colours]\n",
        "labels = keypoint_def[\"Name\"].values.tolist()\n",
        "\n",
        "# Utility for reading an image and for getting its annotations.\n",
        "def get_dog(name):\n",
        "    data = json_dict[name]\n",
        "    img_data = plt.imread(os.path.join(IMG_DIR, data[\"img_path\"]))\n",
        "    # If the image is RGBA convert it to RGB.\n",
        "    if img_data.shape[-1] == 4:\n",
        "        img_data = img_data.astype(np.uint8)\n",
        "        img_data = Image.fromarray(img_data)\n",
        "        img_data = np.array(img_data.convert(\"RGB\"))\n",
        "    data[\"img_data\"] = img_data\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "bhVb7-ENCIwn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 显示keypoint"
      ],
      "metadata": {
        "id": "pheTO0XkKha4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parts of this code come from here:\n",
        "# https://github.com/benjiebob/StanfordExtra/blob/master/demo.ipynb\n",
        "def visualize_keypoints(images, keypoints):\n",
        "    fig, axes = plt.subplots(nrows=len(images), ncols=2, figsize=(16, 12))\n",
        "    [ax.axis(\"off\") for ax in np.ravel(axes)]\n",
        "\n",
        "    for (ax_orig, ax_all), image, current_keypoint in zip(axes, images, keypoints):\n",
        "        ax_orig.imshow(image)\n",
        "        ax_all.imshow(image)\n",
        "\n",
        "        # If the keypoints were formed by `imgaug` then the coordinates need\n",
        "        # to be iterated differently.\n",
        "        if isinstance(current_keypoint, KeypointsOnImage):\n",
        "            for idx, kp in enumerate(current_keypoint.keypoints):\n",
        "                ax_all.scatter(\n",
        "                    [kp.x], [kp.y], c=colours[idx], marker=\"x\", s=50, linewidths=5\n",
        "                )\n",
        "        else:\n",
        "            current_keypoint = np.array(current_keypoint)\n",
        "            # Since the last entry is the visibility flag, we discard it.\n",
        "            current_keypoint = current_keypoint[:, :2]\n",
        "            for idx, (x, y) in enumerate(current_keypoint):\n",
        "                ax_all.scatter([x], [y], c=colours[idx], marker=\"x\", s=50, linewidths=5)\n",
        "\n",
        "    plt.tight_layout(pad=2.0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Select four samples randomly for visualization.\n",
        "samples = list(json_dict.keys())\n",
        "num_samples = 4\n",
        "selected_samples = np.random.choice(samples, num_samples, replace=False)\n",
        "\n",
        "images, keypoints = [], []\n",
        "\n",
        "for sample in selected_samples:\n",
        "    data = get_dog(sample)\n",
        "    image = data[\"img_data\"]\n",
        "    keypoint = data[\"joints\"]\n",
        "\n",
        "    images.append(image)\n",
        "    keypoints.append(keypoint)\n",
        "\n",
        "visualize_keypoints(images, keypoints)"
      ],
      "metadata": {
        "id": "c9qhcDYXCKZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 构建数据生成器"
      ],
      "metadata": {
        "id": "iGYnAskdCT6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KeyPointsDataset(keras.utils.Sequence):\n",
        "    def __init__(self, image_keys, aug, batch_size=BATCH_SIZE, train=True):\n",
        "        self.image_keys = image_keys\n",
        "        self.aug = aug\n",
        "        self.batch_size = batch_size\n",
        "        self.train = train\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_keys) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.image_keys))\n",
        "        if self.train:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        image_keys_temp = [self.image_keys[k] for k in indexes]\n",
        "        (images, keypoints) = self.__data_generation(image_keys_temp)\n",
        "\n",
        "        return (images, keypoints)\n",
        "\n",
        "    def __data_generation(self, image_keys_temp):\n",
        "        batch_images = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, 3), dtype=\"int\")\n",
        "        batch_keypoints = np.empty(\n",
        "            (self.batch_size, 1, 1, NUM_KEYPOINTS), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        for i, key in enumerate(image_keys_temp):\n",
        "            data = get_dog(key)\n",
        "            current_keypoint = np.array(data[\"joints\"])[:, :2]\n",
        "            kps = []\n",
        "\n",
        "            # To apply our data augmentation pipeline, we first need to\n",
        "            # form Keypoint objects with the original coordinates.\n",
        "            for j in range(0, len(current_keypoint)):\n",
        "                kps.append(Keypoint(x=current_keypoint[j][0], y=current_keypoint[j][1]))\n",
        "\n",
        "            # We then project the original image and its keypoint coordinates.\n",
        "            current_image = data[\"img_data\"]\n",
        "            kps_obj = KeypointsOnImage(kps, shape=current_image.shape)\n",
        "\n",
        "            # Apply the augmentation pipeline.\n",
        "            (new_image, new_kps_obj) = self.aug(image=current_image, keypoints=kps_obj)\n",
        "            batch_images[i,] = new_image\n",
        "\n",
        "            # Parse the coordinates from the new keypoint object.\n",
        "            kp_temp = []\n",
        "            for keypoint in new_kps_obj:\n",
        "                kp_temp.append(np.nan_to_num(keypoint.x))\n",
        "                kp_temp.append(np.nan_to_num(keypoint.y))\n",
        "\n",
        "            # More on why this reshaping later.\n",
        "            batch_keypoints[i,] = np.array(kp_temp).reshape(1, 1, 24 * 2)\n",
        "\n",
        "        # Scale the coordinates to [0, 1] range.\n",
        "        batch_keypoints = batch_keypoints / IMG_SIZE\n",
        "\n",
        "        return (batch_images, batch_keypoints)"
      ],
      "metadata": {
        "id": "ub61SxR0CYC7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_aug = iaa.Sequential(\n",
        "    [\n",
        "        iaa.Resize(IMG_SIZE, interpolation=\"linear\"),\n",
        "        iaa.Fliplr(0.3),\n",
        "        # `Sometimes()` applies a function randomly to the inputs with\n",
        "        # a given probability (0.3, in this case).\n",
        "        iaa.Sometimes(0.3, iaa.Affine(rotate=10, scale=(0.5, 0.7))),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_aug = iaa.Sequential([iaa.Resize(IMG_SIZE, interpolation=\"linear\")])"
      ],
      "metadata": {
        "id": "2onAEyFBCbBb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 切割数据集"
      ],
      "metadata": {
        "id": "nt3TkJS2CfbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(samples)\n",
        "train_keys, validation_keys = (\n",
        "    samples[int(len(samples) * 0.15) :],\n",
        "    samples[: int(len(samples) * 0.15)],\n",
        ")"
      ],
      "metadata": {
        "id": "Vx1jXZrbCfG4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = KeyPointsDataset(train_keys, train_aug)\n",
        "validation_dataset = KeyPointsDataset(validation_keys, test_aug, train=False)\n",
        "\n",
        "print(f\"Total batches in training set: {len(train_dataset)}\")\n",
        "print(f\"Total batches in validation set: {len(validation_dataset)}\")\n",
        "\n",
        "sample_images, sample_keypoints = next(iter(train_dataset))\n",
        "assert sample_keypoints.max() == 1.0\n",
        "assert sample_keypoints.min() == 0.0\n",
        "\n",
        "sample_keypoints = sample_keypoints[:4].reshape(-1, 24, 2) * IMG_SIZE\n",
        "visualize_keypoints(sample_images[:4], sample_keypoints)\n"
      ],
      "metadata": {
        "id": "QoMiBdsiCis8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 构建模型"
      ],
      "metadata": {
        "id": "9Ox5HbQ-Cq--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    # Load the pre-trained weights of MobileNetV2 and freeze the weights\n",
        "    backbone = keras.applications.MobileNetV2(\n",
        "        weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    )\n",
        "    backbone.trainable = False\n",
        "\n",
        "    inputs = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "    x = backbone(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.SeparableConv2D(NUM_KEYPOINTS, kernel_size=5, strides=1, activation=\"relu\")(x)\n",
        "    outputs = layers.SeparableConv2D(NUM_KEYPOINTS, kernel_size=3, strides=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs, name=\"keypoint_detector\")"
      ],
      "metadata": {
        "id": "JflprhESCtob"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(1e-4))\n",
        "get_model().summary()"
      ],
      "metadata": {
        "id": "xXwVvhrCCyR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 预览模型架构"
      ],
      "metadata": {
        "id": "JPrWlo3sKyzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "nDZr5xaGK1zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 训练"
      ],
      "metadata": {
        "id": "RzX-5h1iQlD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, validation_data=validation_dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "4WMPACf9CwLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 显示训练成果"
      ],
      "metadata": {
        "id": "sXQcCBW_C533"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_val_images, sample_val_keypoints = next(iter(validation_dataset))\n",
        "sample_val_images = sample_val_images[:4]\n",
        "sample_val_keypoints = sample_val_keypoints[:4].reshape(-1, 24, 2) * IMG_SIZE\n",
        "predictions = model.predict(sample_val_images).reshape(-1, 24, 2) * IMG_SIZE\n",
        "\n",
        "# Ground-truth\n",
        "visualize_keypoints(sample_val_images, sample_val_keypoints)\n",
        "\n",
        "# Predictions\n",
        "visualize_keypoints(sample_val_images, predictions)"
      ],
      "metadata": {
        "id": "BtwBDoS5C71L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
