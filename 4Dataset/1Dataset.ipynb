{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJeyZiIcoHv"
      },
      "source": [
        "!gdown --id '153DyBFeQCCl3-85M0SalJz8z0W_ZKYX5' --output parking.zip # 下载dataset\n",
        "!unzip parking.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2SFnXowc96j"
      },
      "source": [
        "import pathlib\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6L2gC1Jk2i8"
      },
      "source": [
        "read_file_time = 0\n",
        "\n",
        "def load_and_preprocess_from_path_label(path, label):\n",
        "  global read_file_time\n",
        "  read_file_time += 1\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize(img, (128, 128))\n",
        "  img /= 255.0\n",
        "  return img, label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlZpxivWlD_q"
      },
      "source": [
        "label_map = {'free': 0, 'occupy': 1}\n",
        "\n",
        "train_files_paths = [str(file_path) for file_path in pathlib.Path('./parking/train').glob('*/*')]\n",
        "train_files_label = [label_map[pathlib.Path(file_path).parent.name] for file_path in train_files_paths]\n",
        "image_count = len(train_files_paths)\n",
        "\n",
        "# 构建image, label数据集\n",
        "ds = tf.data.Dataset.from_tensor_slices((train_files_paths, train_files_label))\n",
        "image_label_ds = ds.map(load_and_preprocess_from_path_label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cwVHcCvqLC7"
      },
      "source": [
        "# 设置一个和数据集大小一致的 shuffle buffer size（随机缓冲区大小）以保证数据\n",
        "# 被充分打乱。\n",
        "ds = image_label_ds.shuffle(buffer_size=image_count)\n",
        "ds = ds.repeat()\n",
        "ds = ds.batch(batch_size=100)\n",
        "# 当模型在训练的时候，`prefetch` 使数据集在后台取得 batch。\n",
        "ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Convolution2D(24, 3, 3, input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Convolution2D(48, 3, 3),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(ds, epochs=30, steps_per_epoch=300)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}