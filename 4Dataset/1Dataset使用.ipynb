{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Dataset.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "RZJeyZiIcoHv"
   },
   "source": [
    "!gdown --id '153DyBFeQCCl3-85M0SalJz8z0W_ZKYX5' --output parking.zip # 下载dataset\n",
    "!unzip parking.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c2SFnXowc96j"
   },
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h6L2gC1Jk2i8"
   },
   "source": [
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (128, 128))\n",
    "    img /= 255.0\n",
    "    return img, label"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jlZpxivWlD_q"
   },
   "source": [
    "label_map = {'free': 0, 'occupy': 1}\n",
    "\n",
    "train_files_paths = [str(file_path) for file_path in pathlib.Path('./parking/train').glob('*/*')]\n",
    "train_label = [label_map[pathlib.Path(file_path).parent.name] for file_path in train_files_paths]\n",
    "\n",
    "BATCH_SIZE = 35\n",
    "image_count = len(train_label)\n",
    "steps_per_epoch = tf.math.ceil(image_count / BATCH_SIZE).numpy()\n",
    "\n",
    "# 构建缓存数据集，打乱数据，无限循环训练集\n",
    "ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((train_files_paths, train_label))\n",
    "        .map(load_and_preprocess_from_path_label)\n",
    "        .cache()\n",
    "        .shuffle(buffer_size=image_count)\n",
    "        .repeat()\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G4xMmiiBKQ51"
   },
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Convolution2D(24, 3, 3, input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Convolution2D(48, 3, 3),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 每次更新300步，每次取35图片训练\n",
    "model.fit(ds, epochs=30, steps_per_epoch=steps_per_epoch)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JqZ-DQNCvXQj"
   },
   "source": [
    "# 构建验证集\n",
    "valid_files_paths = [str(file_path) for file_path in pathlib.Path('./parking/test').glob('*/*')]\n",
    "valid_label = [label_map[pathlib.Path(file_path).parent.name] for file_path in valid_files_paths]\n",
    "\n",
    "# 使用缓存，每次验证100个\n",
    "valid_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((valid_files_paths, valid_label))\n",
    "        .map(load_and_preprocess_from_path_label)\n",
    "        .cache()\n",
    "        .batch(100)\n",
    "        .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_NWpi-EBvv0m"
   },
   "source": [
    "model.evaluate(valid_ds, verbose=2)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}